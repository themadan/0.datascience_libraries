{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zku1vUo1OQn",
        "colab_type": "text"
      },
      "source": [
        "# Keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE-St3P0wfFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "169Eo--d1ZwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes=10\n",
        "iterations=int(100)\n",
        "learning_rate=0.001\n",
        "batch_size=128\n",
        "\n",
        "conv1_filters=32\n",
        "conv2_filters=64\n",
        "fc1_units=1024\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFoLt8ba-MRV",
        "colab_type": "text"
      },
      "source": [
        "# prepare mnist data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSwQHY7a20WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import  mnist\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP8DPEs-4sYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test=np.array(x_train,np.float32),np.array(x_test,np.float32)\n",
        "x_train,x_test=x_train/255,x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lL74SCJ-R4g",
        "colab_type": "text"
      },
      "source": [
        "# use tf.data to shuffle and batch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkYf4_1Y-Bqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=tf.data.Dataset.from_tensor_slices((x_train,y_train)) # x_train ra y_train lai suffal ta garxa tara corrosponding label sangai shuffle garxa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_1cXltC-itU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkf0sXuL-4Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x,w,b,strides=1):\n",
        "  x=tf.nn.conv2d(x,w,strides=[1,strides,strides,1],padding='SAME')\n",
        "  x=tf.nn.bias_add(x,b)\n",
        "  return tf.nn.relu(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUrNP3iq_Qtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxpool2d(x,k=2):\n",
        "  return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k],padding='SAME')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Soe4KYu2AN8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_normal=tf.initializers.RandomNormal()\n",
        "weights={\n",
        "    'c1':tf.Variable(random_normal([5,5,1,conv1_filters])),\n",
        "    'c2':tf.Variable(random_normal([5,5,conv1_filters,conv2_filters])),\n",
        "    'f1':tf.Variable(random_normal([7*7*64,fc1_units])),\n",
        "    'out':tf.Variable(random_normal([fc1_units,num_classes]))\n",
        "\n",
        "\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd1BBp2IBMKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biases={\n",
        "    'bc1':tf.Variable(tf.zeros([conv1_filters])),\n",
        "    'bc2':tf.Variable(tf.zeros([conv2_filters])),\n",
        "    'bfc1':tf.Variable(tf.zeros([fc1_units])),\n",
        "    'bout':tf.Variable(tf.zeros([num_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alZIQTufCMLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_net(x):\n",
        "  x=tf.reshape(x,[-1,28,28,1])\n",
        "  conv1=conv2d(x,weights['c1'],biases['bc1'])\n",
        "  conv1=maxpool2d(conv1,k=2)\n",
        "  conv2=conv2d(x,weights['c2'],biases['bc2'])\n",
        "  conv2=maxpool2d(conv2,k=2)\n",
        "  fc1=tf.reshape(conv2,[-1,weights['fc'].get_shape().as_list()[0]])\n",
        "  fc1=tf.add(tf.matmul(fc1,weights['fc'],biases['bfc1']))\n",
        "  fc1=tf.nn.relu(fc1)\n",
        "  out=tf.add(tf.matmul(fc1,weights['out']),biases['bout'])\n",
        "  return tf.nn.softmax(out)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlGJ7UelFZWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy(y_pred,y_true):\n",
        "  y_true=tf.one_hot(y_true,depth=num_classes)\n",
        "  y_pred=tf.clip_by_value(y_pred,1e-9,1.)\n",
        "  return tf.reduce_mean(tf.cast(correct_prediction,tf.float32),axis=-1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YSSvVtUG__6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_pred,y_true):\n",
        "  correct_prediction=tf.equal(tf.argmax(y_pred,1),tf.cast(y_true,tf.int64))\n",
        "  return tf.reduce_mean(tf.cast(correct_prediction,tg.float32),axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U33yRnxMiG76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=tf.optimizers.Adam(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj0jLmk_iQ5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainable_weights=[]\n",
        "for i in weights:\n",
        "  trainable_weights.append(weights[i])\n",
        "for i in  biases:\n",
        "  trainable_weights.append(biases[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cv22zKzi4-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(x,y,trainable_weights):\n",
        "  with tf.GradientTape() as g:\n",
        "    pred=conv_net(x)\n",
        "    loss=cross_entropy(pred,y)\n",
        "  gradients=g.gradient(loss,trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradient,trainable_weights))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puoE781qjErm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "a91c7167-83a9-43fb-ed18-261515fb1c8c"
      },
      "source": [
        "for step,(batch_x,batch_y) in  enumerate(train_data.take(iterations),i):\n",
        "  train(batch_x,batch_y,trainable_weights)\n",
        "  if step%10==0:\n",
        "    pred=conv_net(batch_x)\n",
        "    loss=cross_entropy(pred,batch_y)\n",
        "    acc=accuracy(pred,batc_y)\n",
        "    print('step %i,loss:%f , accurcy: %f' %(step,loss,acc))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-eeaf0769b493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gxYDYUuk79e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}