{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUEDf-O88ZuR",
        "colab_type": "text"
      },
      "source": [
        "# **Tensorflow**\n",
        "# key : tf.modulename.functionanae(parameters)\n",
        "# key :  tensor <=>anydata  (yasari any data lai tensor(matrix) ra any tensor(matrix) lai data ma convert garxa  \n",
        "[tensofflow for python ](https://www.tensorflow.org/)\n",
        "\n",
        "# **STEPS** (TensorFlow ecosystem) [read step by step form tensorflow ecosystem](https://www.tensorflow.org/learn)\n",
        "#C=create input piplines/Load & preprocess data\n",
        "#R=Read Data\n",
        "#U=update parameter /Build, train & reuse models\n",
        "#D=Deploy model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmjO1OciaP4F",
        "colab_type": "text"
      },
      "source": [
        "# 1. Keras custom callback\n",
        "# fit() ,evaluate(),predict() lai pass hunya keyword sabai keras call back hun "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jisZ7xD812Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7157b12f-1726-42e2-d7c7-7c204029fae1"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJlY7OGwa6H5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()\n",
        "x_train=x_train.reshape(60000,784).astype('float32')/255\n",
        "x_test=x_test.reshape(10000,784).astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm6I2RZIdYMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "6747cbe1-e144-4fc4-944c-9adb8155d196"
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFTLvxvEddly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(1,activation='linear',input_dim=784))\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.1),loss='mean_squared_error',metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fVwHnxse6ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "class madan(tf.keras.callbacks.Callback):\n",
        "  def on_train_batch_begin(self,batch,logs=None):\n",
        "    print('Training:Batch{}begin at {}'.format(batch,datetime.now().time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAeYMSt2fr44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1c774108-bbfe-40a2-8b50-f248b67cbc7d"
      },
      "source": [
        "model = get_model()\n",
        "_ = model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=1,\n",
        "          steps_per_epoch=5,\n",
        "          verbose=0,\n",
        "          callbacks=[madan()])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training:Batch0begin at 04:27:38.484607\n",
            "Training:Batch1begin at 04:27:38.718066\n",
            "Training:Batch2begin at 04:27:38.720823\n",
            "Training:Batch3begin at 04:27:38.722752\n",
            "Training:Batch4begin at 04:27:38.724418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pebs4ORyjd0K",
        "colab_type": "text"
      },
      "source": [
        "# application of keras callback applications\n",
        "# *Early stopping at minium loss\n",
        "# yes main application of keras callback is jaba loss minium hunxa taba training afai stop hunuparyo ni ta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2_BZwyGpw8c",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxypMw80py-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
        "\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('The average loss for epoch {} is {:7.2f} and mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ryOtpWGgHqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class EarlyStoppingMinLoss (tf.keras.callbacks.Callback):\n",
        "  def __init__(self,patience=0):\n",
        "    super(EarlyStoppingMinLoss,self).__init__()\n",
        "    self.patience=patience\n",
        "    self.best_weights=None\n",
        "  def on_train_begin(self,logs=None):\n",
        "    self.wait=0\n",
        "    self.stopped_epoch=0\n",
        "    self.best=np.Inf\n",
        "  def on_epoch_end(self,epoch,logs=None):\n",
        "    current=logs.get('loss')\n",
        "    if np.less(current,self.best):\n",
        "      self.best=current \n",
        "      self.wait=0\n",
        "      self.best_weights=self.model.get_weights()\n",
        "    else:\n",
        "      self.wait+=1\n",
        "      if self.wait>=self.patience:\n",
        "        self.stopped_epoch=epoch\n",
        "        self.model.stop_training=True\n",
        "        print('Restoring Model weightd from the end of the best epoch ')\n",
        "        self.model.set_weights(self.best_weights)\n",
        "  def on_train_end (self,logs=None):\n",
        "     if self.stopped_epoch>0:\n",
        "        print('Epoch %05d :early stopping '% (self.stopped_epoch+1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ0A_tRqmxHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "9f9b72c1-213a-4968-f5ab-62c915055873"
      },
      "source": [
        "model=get_model()\n",
        "_=model.fit(x_train,y_train,batch_size=64,steps_per_epoch=5,epochs=30,verbose=0,callbacks=[LossAndErrorPrintingCallback(),EarlyStoppingMinLoss()])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For batch 0, loss is   27.17.\n",
            "For batch 1, loss is  840.05.\n",
            "For batch 2, loss is   23.04.\n",
            "For batch 3, loss is    8.43.\n",
            "For batch 4, loss is    6.88.\n",
            "The average loss for epoch 0 is  181.11 and mean absolute error is    7.96.\n",
            "For batch 0, loss is   10.59.\n",
            "For batch 1, loss is    6.07.\n",
            "For batch 2, loss is    6.09.\n",
            "For batch 3, loss is    4.58.\n",
            "For batch 4, loss is    7.05.\n",
            "The average loss for epoch 1 is    6.87 and mean absolute error is    2.07.\n",
            "For batch 0, loss is    5.01.\n",
            "For batch 1, loss is    4.93.\n",
            "For batch 2, loss is    7.48.\n",
            "For batch 3, loss is    5.41.\n",
            "For batch 4, loss is    4.92.\n",
            "The average loss for epoch 2 is    5.55 and mean absolute error is    1.90.\n",
            "For batch 0, loss is    7.41.\n",
            "For batch 1, loss is    7.01.\n",
            "For batch 2, loss is    9.88.\n",
            "For batch 3, loss is   22.44.\n",
            "For batch 4, loss is   72.23.\n",
            "The average loss for epoch 3 is   23.79 and mean absolute error is    3.84.\n",
            "Restoring Model weightd from the end of the best epoch \n",
            "Epoch 00004 :early stopping \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQZepzcKqDji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}