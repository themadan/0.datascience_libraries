{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PFOl9l0zR1X",
        "colab_type": "text"
      },
      "source": [
        "# **Tensorflow**\n",
        "# key : tf.modulename.functionanae(parameters)\n",
        "# key :  tensor <=>anydata  (yasari any data lai tensor(matrix) ra any tensor(matrix) lai data ma convert garxa  \n",
        "[tensofflow for python ](https://www.tensorflow.org/)\n",
        "\n",
        "# **STEPS** (TensorFlow ecosystem) [read step by step form tensorflow ecosystem](https://www.tensorflow.org/learn)\n",
        "#C=create input piplines/Load & preprocess data\n",
        "#R=Read Data\n",
        "#U=update parameter /Build, train & reuse models\n",
        "#D=Deploy model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTd-IRwzvxUU",
        "colab_type": "text"
      },
      "source": [
        "# **some important note on doing data preprocessing**\n",
        " # 1.simply print the data eg:: **data**\n",
        " # 2.print data with print function eg:: **print(data)**\n",
        " # 3.print the shape of the data eg::**print(data.shape)**\n",
        " # 4.check the data sequence eg:: **list,tuple,set,array,dictionary**\n",
        " # 5.check the data type of elements eg::**int,float,string**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGa3f8ab0V9V",
        "colab_type": "text"
      },
      "source": [
        "# STEP 1:: C=Create input pipline/load & preprocess data\n",
        "\n",
        "# A. **[tf.data](https://www.tensorflow.org/api_docs/python/tf/data)**  api enables you to build complex input pipline from single reusable pices\n",
        "# B.**[tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)**  abstraction represents a sequence of elements ,in which each element consists of one or more components .eg image pipline\n",
        " # i. There is two distinct ways to create Dataset .\n",
        " # * A data source construct a Dataset from data stored in memory or in one or more files.\n",
        " # * A data transformation constructs a datasets a dataset from one or more tf.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE-St3P0wfFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from __future__ import  absolute_import,division,print_function,unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNYt_SP60DlL",
        "colab_type": "code",
        "outputId": "7c1392e4-cbd0-4b54-b7d5-2eee57a3d617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "try :\n",
        "  !pip install -q tf-nightly\n",
        "except Exception:\n",
        "    pass \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 511.7MB 18kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 35.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 52.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 36.0MB/s \n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De1Z8GSD25hC",
        "colab_type": "code",
        "outputId": "f4073b95-9582-4004-e182-98d86f2c868b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Jt_x7I3W0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "np.set_printoptions(precision=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZPkIZez44TF",
        "colab_type": "text"
      },
      "source": [
        "# To create an input pipeline ,you must start with source .\n",
        "# * to construct a Dataset from data in memory ,you can use \n",
        "# **tf.data.Dataset.from_tensors()** or **tf.data.Dataset.from_tensor_slices()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xROp8BaG4NYw",
        "colab_type": "code",
        "outputId": "5fdf8b26-c443-4a43-a5ba-bfb66cbc9b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset =tf.data.Dataset.from_tensor_slices([1,2,3,4])\n",
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGIcD5kw6rmo",
        "colab_type": "code",
        "outputId": "19f5d35a-3a41-4ab2-cffd-0184144d5087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "for i in dataset:\n",
        "  print(i.numpy())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9a92cf306dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J0nc1UT6yrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it=iter(dataset) # iterator le tensor as a  input linxa and auta auta gardai element denxa.\n",
        "print(next(it).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlRheTvF7N0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dataset.reduce(0,lambda state,value:state + value).numpy()) #reduce the all elements to produce a single result."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m5ha_NZ9Uw1",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Structure\n",
        "# * **tf.TypeSpace** ::kun type ko ho tensor Tensor,SparseTensor,RaggedTensor,TensorArray or Dataset   Dinxa\n",
        "# * **Dataset.element_spec** ::tensor ko dataset ko type of each element component denaxa \n",
        "# **note :** shape(n,)  n vanyasi dimension janauxa  x,y =2 dimension..\n",
        " # so yaha n le no of column  which represent the  dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9adqdjJqA5lH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.TypeSpec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE7fOAKR8lx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=tf.data.Dataset.from_tensor_slices(tf.random.uniform([4,10]))\n",
        "# for i in dataset:\n",
        "#    print(i.numpy())\n",
        "dataset.element_spec # NOTE::\n",
        "#print(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEz0R7eh-pc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
        "   (tf.random.uniform([4]),\n",
        "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
        "\n",
        "dataset2.element_spec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXJQFcbS_vZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset3=tf.data.Dataset.zip((dataset,dataset2))\n",
        "dataset3.element_spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUissHLuAw0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset containing a sparse tensor \n",
        "dataset4=tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0,0],[1,2]],values=[1,2],dense_shape=[3,4]))\n",
        "dataset4.element_spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfqI8GNDMrlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use value_type to see the type of value represented by element spec\n",
        "dataset4.element_spec.value_type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N2zFKZMNGOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset5=tf.data.Dataset.from_tensor_slices(tf.random.uniform([4,10],maxval=10,dtype=tf.int32))\n",
        "dataset5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pJGp6LpVgC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for z in dataset5:\n",
        "  print(z.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1eHY-jV0Va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset6 = tf.data.Dataset.from_tensor_slices(\n",
        "   (tf.random.uniform([4]),\n",
        "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
        "\n",
        "dataset6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTPowZDRXypW",
        "colab_type": "text"
      },
      "source": [
        "# Reading input data \n",
        "# * consuming numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytvctd0wW_Rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD FROM .npz file \n",
        "DATA_URL='https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
        "path=tf.keras.utils.get_file('mnist.npz',DATA_URL)\n",
        "with np.load(path) as data:\n",
        "  train_examples=data['x_train']\n",
        "  train_labels=data['y_train']\n",
        "  test_examples=data['x_test']\n",
        "  test_labels=data['y_test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgR3YnyChZA6",
        "colab_type": "text"
      },
      "source": [
        "![iamge here](https://raw.githubusercontent.com/themadan/1.DataScience-libraries/master/Tensorflow(nn-deep%20learning)/1.tensorflow%20ecosystem/images/ndarray%20and%20shape.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITQGNjpFYrsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test=tf.keras.datasets.fashion_mnist.load_data() # mnist data load garxa ani tuple ko rupma return garxa (x_train,y_train),(x_test,y_test) yasari return garxa.\n",
        "print(train[0].shape) #x_train   (60000=no of row=no of image,28=no of row ,28=no of column)\n",
        "print(train[1].shape)# y_train(labels)\n",
        "print(test[0].shape)# x_test\n",
        "print(test[1].shape)#y_test\n",
        "print(train[0][0].shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyPUGjB1Zowu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images,labels=train\n",
        "images=images/255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyNsAKbsZ1Tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=tf.data.Dataset.from_tensor_slices((images,labels))\n",
        "dataset "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l6xb5Ihrbys",
        "colab_type": "text"
      },
      "source": [
        "# Consuming Python Generators\n",
        "# * another common data source that can easily be ingested as a tf.data.Dataset is a python generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYYgBt1laIFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count(stop):\n",
        "  i=0\n",
        "  while i<stop:\n",
        "    yield i\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9kJECw8jjAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n in count(5):\n",
        "  print(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6UVDbrwsO09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOPHq2V_s6AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flowers = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAzHNsBCtA4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_gen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,rotation_range=20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDHqMhmUuhvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images,labels=next(img_gen.flow_from_directory(flowers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcUBcTP5uvYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(images.dtype,images.shape)\n",
        "print(labels.dtype,labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1UmhLN_1N6s",
        "colab_type": "text"
      },
      "source": [
        "# Consuming TFRecord data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqTI6pSEvcIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a dataset that reads all of the examples from two files.\n",
        "fsns_test_file = tf.keras.utils.get_file(\"fsns.tfrec\", \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfO6y76m10PB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=tf.data.TFRecordDataset(filenames=[fsns_test_file])\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZonLidxW21KE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "80696ef1-b4dc-4c1d-a6b4-0ebee91a3f25"
      },
      "source": [
        "raw_example=next(iter(dataset))\n",
        "parsed=tf.train.Example.FromString(raw_example.numpy())\n",
        "parsed.features.feature['iamge/text']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e4ee83033f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_example\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iamge/text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZnOSfrC3xXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}